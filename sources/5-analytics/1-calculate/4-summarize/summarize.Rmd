---
pagetitle: "Kamino"
output: 
  html_document:
    theme: lumen
    css: ["../../../z-assemblers/kamino.css", "../../../z-assemblers/wranglers.css"]
    df_print: paged
    mathjax: NULL
    code_folding: show
    include:
      in_header: "../../../z-assemblers/header.html"
      after_body: "../../../z-assemblers/footer.html"
    #self_contained: false
    #lib_dir: libs
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE, warning=FALSE, echo=FALSE)
options(scipen=999)  # turn-off scientific notation like 1e+48

library(htmltools) # needed to include html snippets
library(tidyverse)

library(knitcitations)
library(bibtex)

```

<div class="activity">
WRANGLERS  
</div>

# Clean data
## I want to fix irregularities in my dataset

> Don't call the world dirty because you forgot to clean your glasses...\
--- Aaron Hill\

After __profiling__ a data source data __quality__ issues may be identified requiring the use of cleaning methods. Typical issues include __duplicate__ records, __missing__ values, and __inconsistent__ or __invalid__ values. Data cleansing provides higher quality and consistent data for downstream analysis.

These are the key areas we'll focus on addressing:

* __De-Duplicate__ : eliminate duplicate records by removing or establishing a unique identifier
* __Missing Values__ : detect null, blank, or empty cells and apply a logic to remove or replace them with new defined or _imputed_ values
* __Invalid Values__ : detect data points that may have been mis-keyed during data entry

Each of these areas have a solution for either __removing__ or __replacing__ the subject values. When a replacement is the preferred
method, imputing a value involves making a reasonable guess at the missing value based on a method of analytic reinforcement. These are the
common approaches to consider:

* using a measure of __central tendency__ (mean, median, mode)
* identify the most __similar cases__ to suggest a candidate value for substitution
* assign a value based on the __probability distribution__ of the non-missing data
* derive the value based on __other features__
* use a __classifier__ model

To illustrate the process, here is an example of before and after running the solutions against a _dirty_ data set.

***

# Section
## Subsection

```{r, message=FALSE, warning=FALSE, echo=TRUE, class.source = 'fold-hide'}

# Fold hide as this is not relevant to the task


```


# Section
## Subsection


```{r, message=FALSE, warning=FALSE, echo=TRUE, class.source = 'fold-show'}



```


# Section
## Subsection


```{r, message=FALSE, warning=FALSE, echo=TRUE, class.source = 'fold-show'}



```



# Section
## Subsection


```{r, message=FALSE, warning=FALSE, echo=TRUE, class.source = 'fold-show'}



```



# Section
## Subsection


```{r, message=FALSE, warning=FALSE, echo=TRUE, class.source = 'fold-show'}



```


# Exercises and practice
## Knime and R practice solutions



# References
## The citations and data sources used for this case

```{r generateBibliography, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}

# cleanbib()
# read.bibtex(file = "./citations.bib")

```


```{r, message=FALSE, warning=FALSE, echo=FALSE}

# echo=FALSE will exclude block from code folding
# Example for including external html content when needed
htmltools::includeHTML("mark-complete-button.html")

```



```{r, child='mark-complete-click.Rmd'}

# JS event handler for button click

```



```{js, message=FALSE, warning=FALSE, echo=FALSE}

// Must be included to position footer
$(function() {
  $('.main-container').after($('.footer'));
})

```

