---
pagetitle: "Kamino"
output:
  bookdown::gitbook: default
documentclass: book
date: "`r Sys.Date()`"
---

```{r, include=FALSE}
knitr::opts_chunk$set(message=FALSE, warning=FALSE, echo=FALSE)
options(scipen=999)  # turn-off scientific notation like 1e+48

library(tidyverse)


```

ANALYTICS


# Cluster
## I want to fix irregularities in my dataset

> Don't call the world dirty because you forgot to clean your glasses...\
--- Aaron Hill\

You want to automatically identify clusters of observations in the data. The idea behind clustering is that of a group of points that are situated in close proximity. In our example, we look at a data set with number of deaths per risk factor. The assumption would be that we can identify groups of data sets that have similar numbers of deaths in several risk factors and thus being in close proximity to each other.

Cluster analysis is a family of algorithms designed to form groups such that the group members are more similar versus non-group members.  Clustering is used for analysing data which does not include pre-labelled classes, or even a class attribute at all. Data instances are grouped together using the concept of maximizing the intraclass similarity and minimizing the interclass similarity.

\item K-means: ...
\item K-medoids: ...
\item Hierarchical: ...
\item Expectation-maximization: ...
\item Density estimation: ...

K-means
k points are randomly chosen as cluster centers, or centroids, and all training instances are plotted and added to the closest cluster. After all instances have been added to clusters, the centroids, representing the mean of the instances of each cluster are re-calculated, with these re-calculated centroids becoming the new centers of their respective clusters.  This iterative process continues until there is no change to the centroids or their membership, and the clusters are considered settled.

A medoid is an entity of the dataset that represents the group to which it was inserted.

Density estimation is the process of estimating the probability density function of a population given in an observation set.  Density estimation produces an estimate for the unobservable population distribution function.

DBSCAN
OPTICS

***

# Section
## Subsection

```{r, message=FALSE, warning=FALSE, echo=TRUE, class.source = 'fold-hide'}

# Fold hide as this is not relevant to the task

df<-read_csv('archetypes/Coffee-2019.csv')

```


# Section
## Subsection


```{r, message=FALSE, warning=FALSE, echo=TRUE, class.source = 'fold-show'}
df1 <- df%>%filter(df['Production Year']== 2011)
df1
distinct_df<-distinct(df1,Warehouse)
distinct_df
```
```{r}
missing_stats <- purrr::map_df(df, ~ sum(is.na(.))) %>%
  gather('Column name', 'Count of missing values')

missing_stats
```


# Section
## Subsection


```{r, message=FALSE, warning=FALSE, echo=TRUE, class.source = 'fold-show'}

library(stats)
df2<-df1[,c(5:9,11)]


clusters <- kmeans(na.omit(df2), 11, iter.max = 20, nstart = 25)


df1$cluster <- as.factor(clusters$cluster)


```



# Section
## Subsection


```{r, message=FALSE, warning=FALSE, echo=TRUE, class.source = 'fold-show'}
library(datasets)
df3<-data(iris)
df3
```



# Section
## Subsection


```{r, message=FALSE, warning=FALSE, echo=TRUE, class.source = 'fold-show'}



```


# Exercises and practice
## Knime and R practice solutions



# References
## The citations and data sources used for this case
