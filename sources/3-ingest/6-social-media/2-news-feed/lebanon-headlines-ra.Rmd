---
title: "Kamino"
output:
  bookdown::gitbook: default
documentclass: book
date: "`r Sys.Date()`"
---

```{r, include=FALSE}

knitr::opts_chunk$set(message=FALSE, warning=FALSE, echo=FALSE)
options(scipen = 999) ## To disable scientific notation

library(rvest)
library(tidyverse)
library(RSelenium)

library(showtext)
## Loading Google fonts (https://fonts.google.com/)
font_add_google("Inconsolata", "inconsolata")
# turn on showtext
showtext_auto()


```


INGEST  

# Aljazeera, Lebanon headlines
## ingest a news feed

```{r, out.width="60%", fig.align="center", fig.cap="Photo by Piotr Chrobot on Unsplash"}

masthead <- "assets/piotr-chrobot-KqEYj1VHA_o-unsplash.jpg"
knitr::include_graphics(masthead, dpi=72)

```


# Text Analytics
## Aljazeera Lebanon

First thing to check is if scraping is permitted.
* __Robots.txt__ : a way to kindly ask webbots, spiders, crawlers, wanderers and the like to access or not access certain parts of a webpage.If the output is true, it means that the bots are allowed to access this path.

```{r,message=FALSE, warning=FALSE, echo=TRUE, class.source='fold-hide'}
library(robotstxt)
paths_allowed(
  path="/where/lebanon/",
  domain = "https://www.aljazeera.com/")
get_robotstxt(domain = "https://www.aljazeera.com/")
```
### Ingestion - Webscraping
Now we can scrape the headlines and links.

```{r,message=FALSE, warning=FALSE, echo=TRUE, class.source='fold-hide'}

rd <- rsDriver(browser = "firefox", port = 8253L)
ffd <- rd$client


ffd$navigate("https://www.aljazeera.com/where/lebanon/")
for (i in 1:6){
load_btn <- ffd$findElement(using = "css selector", "button.show-more-button.big-margin") 
load_btn$clickElement() 
Sys.sleep(2)
}
  
#button.show-more-button.big-margin
url = ffd$getPageSource()[[1]]
page = read_html(url)
headlines <- page %>%
  html_nodes("h3.gc__title") %>%
  html_text()
links <- page %>%
  html_nodes("h3.gc__title a") %>%
  html_attr("href") %>%
  paste("https://www.aljazeera.com", .,sep="")
```

### Creating a data frame
```{r,message=FALSE, warning=FALSE, echo=TRUE, class.source='fold-hide'}
aljazeera_online <- data.frame(headlines,links)
summary <- list()
timearticle <- list()
body <- list()
for (i in aljazeera_online$links){
  url1 <- read_html(i)
  
  summ <- url1 %>%
    html_node("#main-content-area > header > p > em") %>%
    html_text()
  summary <- append(summary, summ)
  
  datar <- url1 %>%
    html_node("#main-content-area > div.article-info-block.css-ti04u9 > div.article-b-l > div.article-dates > 
               div >  span.screen-reader-text") %>%                
    html_text()
    timearticle <- append(timearticle, datar)
  bodies <- url1 %>%
    html_nodes("#main-content-area > div.wysiwyg.wysiwyg--all-content.css-1ck9wyi")%>%
    html_text()
  bodies <- paste (bodies, collapse = " ")
  body <- append(body, bodies)
  
}
aljazeera_online$summary <- as.character(summary)
aljazeera_online$body <- as.character(body)
aljazeera_online$date <- as.character(timearticle)
aljazeera_online
```

### References
#### citations for narrative and data sources

* Narrative and Data Source: Aljazeera,[GO](https://www.aljazeera.com/){target="_blank"} 

